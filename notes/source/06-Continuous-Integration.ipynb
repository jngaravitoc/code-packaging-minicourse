{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically building and testing your code: continuous integration\n",
    "\n",
    "Once you have a test suite for your Python package (even if it is not complete yet), you will want to run it often to check that all tests continue to pass as your package evolves. Doing this automatically is the domain of *continuous integration* and for scientific projects it is most easily done using the free, online services that I discuss in this chapter. Like complete documentation and a comprehensive test suite before, continuous integration is an essential component of a software package that is used by more than a few people and/or receives contributions from outside users (e.g., through pull requests). Setting up continuous integration for your software package will end up saving you lots of time by finding issues with your code quickly and making it less likely that you merge a change that has unexpected, bad consequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why continuous integration?\n",
    "\n",
    "Continuous integration (CI) is the practice of integration all changes into the \"main\" copy of a code base (here, a Python package) on a frequent basis (\"continuously\"). The \"main\" copy in our case is the GitHub repository of the package, that is the bassis of all clones and forks of the code (I assume throughout these notes that the only way the development version of the code is shared is through the GitHub site, even for versions used by the same developer). The main reason to perform continuous integration is to catch any unmergeable changes to the code made in different copies of the code quickly when they can typically be more easily resolved. Continuous integration checks both that the package builds successfully and that it passes the tests in the test suite and this is considered to be a successful integration. \n",
    "\n",
    "To perform continuous integration efficiently, both the build and test system need to be *automated*, that is, they should be able to be run without any human intervention. We have seen how to build a test suite that can be run with a simple ``pytest`` command in the [previous chapter](05-Tests.ipynb); I will discuss how to automate the build with specific examples below. Automating the building and testing of the code is important for taking any human decisions and mistakes out of the loop and for being able to perform the continuous-integration procedure *very often*.\n",
    "\n",
    "What do we in practice mean by \"continuous\", because obviously we aren't running the build-and-test procedure all the time? Continuous qualitatively means that we run the build-and-test procedure every time the code or any of its dependencies change. In practice, it is easier to know when one's own code changes than when the code's dependencies change and we typically run the continuous-integration procedure upon every push of changes to GitHub. That is, we can make multiple commits and run the integration tests each time we push a set of commits to GitHub. Ideally, we would run the integration tests in conjunction with each commit, but since integration tests can be expensive and long-to-run, a compromise of running whenever we think the code is ready for a push to GitHub is good and it is easy to setup with automation services. This does mean that one should push changes to GitHub often, typically at least once a day, to make sure that the continuous integration procedure is run often. The code will also change in response to patches or new features submitted through a pull request and it is good practice to run the continuous-integration procedure *before* merging changes from a pull request. It is easy to set this up to be done automatically and, indeed, having continuous integration set up is essential to being able to merge pull requests for your package, because otherwise it is difficult to know that the proposed changes do not break some unexpected part of your code. One typically runs the continuous-integration procedure for changes to any branch, not just ``master``.\n",
    "\n",
    "The way your code runs also changes when its dependencies change. While one could in principle set up a \"continuous\" check for whether dependencies have changed, in practice this is easiest to spot by running the continuous integration procedure on a fixed schedule in addition to any runs in response to pushes or merged pull requests. That way, you can ensure that the integration tests are run even when the code is going through a stretch of minor development. These fixed-schedule tests could be run daily or weekly, depending on how often you think dependencies might change and/or how quickly you think you need to catch this. One way in which the automated build-and-test of your code is useful is that it shows that there is a working version of your code and how to get it to work, which you can point people to who have issues with installing and running your code.\n",
    "\n",
    "The advantages of continuous integration are many: you will find issues quickly, keep your development version in a working state and, thus, always have a fully-functional version of your code during development (that is, not just at releases), and by making use of automated tools running your integration tests on different types of machines you are able to easily make sure that your code runs on all systems that you support, not just your own. But there are disadvantages as well, the main one being that setting up and maintaining the continuous-integration system takes quite a bit of time and quite often issues that pop up during the integration procedure are due to the way the build-and-test procedure is set up (which can be quite complex for a larger Python package), rather than being due to a real bug in the package itself. For example, the way you install dependencies in the integration step might break and you then have to fix that to keep the continuous-integration procedure working, even though there is likely nothing wrong with your code. Overall, I think even this type of time is well spent, because it is important to know at all times that your code can be built (including its dependencies).\n",
    "\n",
    "There are *many* services available to perform continuous integration of code, because continuous integration is a crucial aspect of all software and software-backed services, allowing bug fixes and updates to be rolled out quickly and often. Continuous integration of course goes far beyond Python packages and is used in the entire range of software, apps, and online services, where it is often combined with *continuous deployment* (CD, leading to the abbreviation CI/CD), the practice of rolling out bug fixes and updates as soon as they are made and pass the integration tests. The most popular CI/CD services are ``Travis CI``, ``Circle CI``, ``Jenkins``, ``appveyor``, and since recently ``GitHub Actions``. I will only discuss ``Travis CI``, ``appveyor``, and ``GitHub Actions`` below, but to a large degree they all work in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous integration with ``Travis CI``\n",
    "\n",
    "``Travis CI`` is a continuous-integration service that is seamlessly integrated with GitHub and is free for open-source projects, generously providing you with multiple runners for your build-and-test integrations. The way ``Travis CI`` works is that you connect it to your GiHub account, give it access to your repository, and once configured it will automatically run your build and test suites every time you push to any branch and every time somebody opens a pull request. It will notify you when things go wrong (or when things go right! But that's not typically as interesting...) and can send the results from tests on to other services (e.g., those that parse and display your test coverage statistics).\n",
    "\n",
    "To get started, go to [https://travis-ci.com/](https://travis-ci.com/) and sign up with your GitHub account. You then need to give ``Travis CI`` permission to access your account's information. Once you're back at ``travis-ci.com``, you can click on your profile picture to bring up a big green ``Activate`` button, press this to activate the GitHub Apps integration which ``Travis CI`` uses to start testing and deploying on ``Travis CI``. Once you have clicked this, you will see a list of your repositories, if you click on the repository that you want to add to ``Travis CI``, you will be brought to its page, which looks like this for the example package ``exampy`` at first"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-start.png\n",
    "    :width: 86%\n",
    "    :align: center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start building and testing our package with ``Travis CI``, we have to add a ``.travis.yml`` configuration file to the top-level directory of our repository and push this to GitHub. This ``.travis.yml`` file will contain *all* of the information to configure the build-and-test procedure on ``Travis CI``. I will go over all of the parts in due course, so let's start with the simplest possible configuration for our ``exampy`` project, which looks like\n",
    "```\n",
    "language: python\n",
    "\n",
    "python:\n",
    "  - \"3.7\"\n",
    "\n",
    "install:\n",
    "  - python setup.py develop\n",
    "\n",
    "script:\n",
    "  - echo 0\n",
    "```\n",
    "This configuration file does only the most basic things: (i) it states what the language of the code (Python) and what version to use, (ii) it installs the code in the ``install:`` section, and (iii) it has a trivial statement in the ``script:`` section, which will later contain the running of the test suite. The reason that we need to add the trivial statement in the ``script:`` section is that without this section, ``Travis CI`` will label the run as failed. If you add this file to the GitHub repository and push it to GitHub, ``Travis CI`` is notified by GitHub that a change occurred in the repository, and ``Travis CI`` starts running the continuous integration procedure; the page on ``Travis CI`` will change to something like"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-firstrun.png\n",
    "    :width: 86%\n",
    "    :align: center    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(where the run should be \\#1 for you, I messed up my own first run...). If you scroll down, you see the full log of what happened and you will see that ``Travis CI`` clones your repository, sets up Python, runs the ``install:`` section, followed by the ``script:`` section:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-firstrun2.png\n",
    "    :width: 86%\n",
    "    :align: center    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to run our test suite with ``pytest`` and print the test coverage information using the ``pytest-cov`` plugin. To do this, we need to install ``pytest`` and the ``pytest-cov`` plugin in the ``install:`` section as well, and then run our test suite in the ``script:`` section, such that ``.travis.yml`` file now looks as follows\n",
    "```\n",
    "language: python\n",
    "\n",
    "python:\n",
    "  - \"3.7\"\n",
    "\n",
    "install:\n",
    "  - pip\tinstall\tpytest\n",
    "  - pip\tinstall\tpytest-cov\n",
    "  - python setup.py develop\n",
    "\n",
    "script:\n",
    "  - pytest -v tests/ --cov=exampy/\n",
    "```\n",
    "Pushing this change to GitHub, ``Travis CI`` automatically clones the updated repository and runs the build-and-test procedure. However, the tests fail, with the pertinent part of the log being"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-secondrun.png\n",
    "    :width: 86%\n",
    "    :align: center    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tests failed, because we forgot to install ``scipy``, which is not a dependency of the ``exampy`` package itself (and, thus, we didn't list it in the ``install_requires`` section of the ``setup.py`` file), but it is a dependency of the test suite, because in one test we compare the ``exampy.integrate.simps`` procedure to numerical integration in ``scipy``. Thus, we need to also install ``scipy``, using the following ``.travis.yml``\n",
    "```\n",
    "language: python\n",
    "\n",
    "python:\n",
    "  - \"3.7\"\n",
    "\n",
    "install:\n",
    "  - pip\tinstall\tpytest\n",
    "  - pip\tinstall\tpytest-cov\n",
    "  - pip install scipy\n",
    "  - python setup.py develop\n",
    "\n",
    "script:\n",
    "  - pytest -v tests/ --cov=exampy/\n",
    "```\n",
    "This time the tests pass without a hitch!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-thirdrun.png\n",
    "    :width: 86%\n",
    "    :align: center    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``.travis.yml`` configuration file has *lots* of possible sections to customize your build and test runs in any way that you want, which are documented in full [here](https://config.travis-ci.com/). When you are using the linux operating system (the default), you have access to a full Ubuntu distribution and you can run arbitrary commands in the sections ``install:``, ``before_install:`` (which contains commands to run before the installation of your code; technically it would have been better to install the test dependencies in the ``before_install:`` section, or in the ``before_script:`` section [see below] because they are not necessary for the code's installation itself), ``script:``, ``before_script:``, etc. There are also many other sections that allow you to install some dependencies more easily, to setup environment variables, to run your build-and-test integrations with different versions of dependencies (and Python itself), and there are sections ``after_success:`` and ``after_failure:`` to customize what ``Travis CI`` does upon successful or unsuccessful execution of your build-and-test run. In the remainder of this section, I will cover some of the most commonly-used customizations.\n",
    "\n",
    "As a first example of a customization, let's say we want to explicitly specify the ``numpy`` version used by our code. To do this, we add an ``env:`` section that contains an environment variable ``NUMPY_VERSION`` that we set to the desired version. Then we can use this environment variable in the rest of the configuration file, e.g., as\n",
    "```\n",
    "language: python\n",
    "\n",
    "python:\n",
    "  - \"3.7\"\n",
    "\n",
    "env:\n",
    "  - NUMPY_VERSION=1.18\n",
    "\n",
    "before_install:\n",
    "  - pip install numpy==$NUMPY_VERSION\n",
    "\n",
    "install:\n",
    "  - python setup.py develop\n",
    "\n",
    "before_script:\n",
    "  - pip\tinstall\tpytest\n",
    "  - pip\tinstall\tpytest-cov\n",
    "  - pip install scipy\n",
    "\n",
    "script:\n",
    "  - pytest -v tests/ --cov=exampy/\n",
    "```\n",
    "where we have now explicitly included the ``numpy`` dependency install in the ``before_install:`` section (previously, we used the default ``numpy`` version available for this ``Travis CI`` disk image) and we have moved the installations that are only necessary for the test suite to the ``before_script:`` section. Pushing this change to GitHub, the log on ``Travis CI`` now shows that the requested version of ``numpy`` is installed, with the relevant part of the log being:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-specifynumpy.png\n",
    "    :width: 86%\n",
    "    :align: center    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set multiple environment variables in the ``env:`` section, but note that all definitions should be part of a *single* dash. E.g., to also specify the ``scipy`` version, do\n",
    "```\n",
    "language: python\n",
    "\n",
    "python:\n",
    "  - \"3.7\"\n",
    "\n",
    "env:\n",
    "  - NUMPY_VERSION=1.18\n",
    "    SCIPY_VERSION=1.4\n",
    "\n",
    "before_install:\n",
    "  - pip install numpy==$NUMPY_VERSION\n",
    "\n",
    "install:\n",
    "  - python setup.py develop\n",
    "\n",
    "before_script:\n",
    "  - pip\tinstall\tpytest\n",
    "  - pip\tinstall\tpytest-cov\n",
    "  - pip install scipy==$SCIPY_VERSION\n",
    "\n",
    "script:\n",
    "  - pytest -v tests/ --cov=exampy/\n",
    "```\n",
    "rather than\n",
    "```\n",
    "...\n",
    "env:\n",
    "  - NUMPY_VERSION=1.18\n",
    "  - SCIPY_VERSION=1.4\n",
    "...\n",
    "```\n",
    "because the latter would create two jobs, one with the ``numpy`` version set, the other with the ``scipy`` version set (see below). Another use of environment variables is to split your tests into sets to be executed in parallel, by explicitly setting the test files fed to ``pytest`` as an environment variable.\n",
    "\n",
    "One of the great advantages of using a cloud-based continuous-integration system is that you can easily test your code with different versions of Python and your code's dependencies. ``Travis CI`` allows you to easily build *matrices* of jobs, by taking multiple values listed in some of the configuration sections. For example, if you list two major Python versions in the ``python:`` section and three minor ``numpy`` versions in the ``env:`` section as above, following the recommendations from a recent [proposal](https://numpy.org/neps/nep-0029-deprecation_policy.html) for which Python and ``numpy`` versions packages should support, ``Travis CI`` will run 6 different jobs, one for each combination of Python and ``numpy`` version. In the example that we have been considering, this gives the following ``.travis.yml``:\n",
    "```\n",
    "language: python\n",
    "\n",
    "python:\n",
    "  - \"3.8\"\n",
    "  - \"3.7\"\n",
    "\n",
    "env:\n",
    "  - NUMPY_VERSION=1.18\n",
    "  - NUMPY_VERSION=1.17\n",
    "  - NUMPY_VERSION=1.16\n",
    "\n",
    "before_install:\n",
    "  - pip install numpy==$NUMPY_VERSION\n",
    "\n",
    "install:\n",
    "  - python setup.py develop\n",
    "\n",
    "before_script:\n",
    "  - pip\tinstall\tpytest\n",
    "  - pip\tinstall\tpytest-cov\n",
    "  - pip install scipy\n",
    "\n",
    "script:\n",
    "  - pytest -v tests/ --cov=exampy/\n",
    "```\n",
    "Pushing this to GitHub, we see that the ``Travis CI`` page for the current build-and-test integration looks as follows when the integration test is in progress:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-pythonnumpymatrix.png\n",
    "    :width: 86%\n",
    "    :align: center    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than seeing the log for a single job, we now see an overview of the six created jobs for the six combinations of Python and ``numpy`` versions. Some of these run in parallel. Clicking on one of the jobs will bring up the log for that particular job and ``Travis CI`` will report the status of each job as either a success or a failure; the entire combination only succeeds of all component jobs succeed (unless you [allow failures](https://docs.travis-ci.com/user/build-matrix/#rows-that-are-allowed-to-fail)). Once all jobs finish running, the final status looks as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-pythonnumpymatrix2.png\n",
    "    :width: 86%\n",
    "    :align: center    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that one job failed! Another thing you notice when looking at the duration of each job is that the Python v3.8 / ``numpy`` v1.18 and all of the Python v3.7 finish in about 30 seconds, the other two Python v3.8 jobs run for about three minutes. Upon inspection of the logs, it becomes clear that the reason for this is that for these two jobs, no binary wheels for ``numpy`` are available; I will discuss binary wheels more in [Chapter 7](07-Package-Release.ipynb), but for now the important thing to know about them is that they allow you to install a package with ``pip`` without building it on your computer (which is what ``pip`` normally does). Thus, for these two versions, ``pip install numpy`` builds ``numpy`` from source and this takes a while. For the Pythonv3.8 / ``numpy`` v1.17 combination, this build actually fails on ``Travis CI``, which is the cause of this job's failure.\n",
    "\n",
    "When your code includes a few dependencies that take a long (more than a dozen or so seconds) time to build from source (e.g., ``numpy`` *and* ``scipy``), it is beneficial to use the [Anaconda](https://www.anaconda.com/distribution/) Python distribution, which includes built versions of many packages that you might use. Because the entire Anaconda distribution is large and your ``Travis CI`` runs would have to download it every time, it is good to use the [Miniconda](https://docs.conda.io/en/latest/miniconda.html) version of Anaconda instead, which is a bare-bones version of Anaconda that comes with very few packages pre-installed to create a light-weight distribution. Using Miniconda requires us to add a few lines to the ``before_install:`` section to download Miniconda, set it up, and use it to install the dependencies. Note that we need to make sure that Miniconda gets set up for the same Python version that we requested in the ``python:`` section, by using the ``$TRAVIS_PYTHON_VERSION`` environment variable that ``Travis CI``` automatically defines. \n",
    "\n",
    "Re-writing the example above using Miniconda looks like\n",
    "```\n",
    "language: python\n",
    "\n",
    "python:\n",
    "  - \"3.8\"\n",
    "  - \"3.7\"\n",
    "\n",
    "env:\n",
    "  - NUMPY_VERSION=1.18.1\n",
    "  - NUMPY_VERSION=1.17,4\n",
    "  - NUMPY_VERSION=1.16.6\n",
    "\n",
    "before_install:\n",
    "  - wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
    "  - bash miniconda.sh -b -p $HOME/miniconda\n",
    "  - export PATH=\"$HOME/miniconda/bin:$PATH\"\n",
    "  - hash -r\n",
    "  - conda config --set always_yes yes --set changeps1 no\n",
    "  - conda update conda\n",
    "  - conda config --add channels conda-forge\n",
    "  - conda create -n test-environment python=$TRAVIS_PYTHON_VERSION \"numpy==$NUMPY_VERSION\" scipy pip\n",
    "  - source activate test-environment\n",
    "\n",
    "install:\n",
    "  - python setup.py develop\n",
    "\n",
    "before_script:\n",
    "  - pip\tinstall\tpytest\n",
    "  - pip\tinstall\tpytest-cov\n",
    "\n",
    "script:\n",
    "  - pytest -v tests/ --cov=exampy/\n",
    "```\n",
    "Note that I have taken advantage of the fact that ``scipy`` can also be more easily installed using ``conda`` to simply include it in the main ``conda create`` command in the ``before_install:`` section. I also specified the exact version of ``numpy`` to use, because otherwise for, e.g., v1.17 ``conda`` tries to install v1.17.0 (which in this case fails, because it does not exist in Anaconda for Python 3.8). Finally, it's important to note that once you use conda, the Python version that is used is that given to the ``conda create`` command, which does not have to be the same as the one specified in the ``python:`` section. In particular, currently ``Travis CI`` does not contain Python v3.8 and it therefore has to download it first; you could simply use Python v3.7 in the ``python:`` section and then specify ``python=3.8`` in the ``conda create`` command to actually use Python v3.8 for the build and test, but in practice it's easier to keep the two Python versions consistent by using the ``$TRAVIS_PYTHON_VERSION`` environment variable.\n",
    "\n",
    "This run now was successful, with the overview at the end looking like\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-pythonnumpymatrixsuccess.png\n",
    "    :width: 86%\n",
    "    :align: center    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each job now takes about a minute to run, showing that using Miniconda significantly speeds up the run compared to building ``numpy`` from source (which above led to a > 2 minute job time; building ``scipy`` from source would more than double that).\n",
    "\n",
    "At this point, you email inbox will be filled with emails from ``Travis CI`` telling you about the status of each integration run. You typically do not want to be updated about the status of every run, but simply when the status changes. For example, if a set of runs all end successfully, it's not that useful to get an email about this every time, but if a run suddenly fails, you will want to know that. Similarly, if your runs have been failing, it's useful to know when they start passing again (although that you will more likely be checking on the website directly). To only get notified upon a change in status from success to failure or failure to success, add a section to your ``.travis.yml`` file at the end that looks like\n",
    "```\n",
    "notifications:\n",
    "  email:\n",
    "    recipients:\n",
    "      - YOUR_EMAIL\n",
    "    on_success: change\n",
    "    on_failure: change\n",
    "```\n",
    "\n",
    "Other useful parts of the ``.travis.yml`` file that I will not discuss in detail are:\n",
    "\n",
    "* ``addons:`` allows you to specify dependencies that can be installed using, e.g., standard linux tools like ``apt-get``. For example, to use the GNU scientific library, use\n",
    "```\n",
    "addons:\n",
    "  apt:\n",
    "    packages:\n",
    "      - libgsl0-dev\n",
    "```\n",
    "\n",
    "* If your tests make plots, you will run into errors, because the plots cannot be displayed. To avoid those, include the ``xvfb`` service that allows you to run graphical applications without a display:\n",
    "```\n",
    "services:\n",
    "  - xvfb\n",
    "```\n",
    "\n",
    "* Building a matrix of jobs by multiplying options set in sections such as ``python:`` and ``env:`` quickly leads to large build matrices. If you just want to include an additional job with different parameters, you can include individual jobs in the ``matrix:`` section, e.g., include a single job that uses Python v3.6 and ``numpy`` v1.18.1 with\n",
    "```\n",
    "matrix:\n",
    "  include:\n",
    "    - python: \"3.6\"\n",
    "      env: NUMPY_VERSION=1.18.1\n",
    "```\n",
    "\n",
    "  You can also [exclude](https://docs.travis-ci.com/user/build-matrix/#excluding-jobs) jobs from the matrix. Full documentation on the build matrix is given [here](https://docs.travis-ci.com/user/build-matrix/).\n",
    "  \n",
    "Finally, by default, ``Travis CI`` will run when you push a new commit or set of commits to GitHub (for any branch) or when someone opens a pull request (in that case, ``Travis CI`` will automatically add status updates on whether the integration tests pass to the pull request's page). If in addition to this, you want the build of, say, your ``master`` branch to happen at least weekly whether or not a change occurred, you can do this with a \"cron job\" by going to your package's ``Travis CI`` page and navigating to the \"Settings\" under the \"More Options\" menu. There, there is a \"Cron Jobs\" part where you can choose a branch, how often to run (daily, weekly, or monthly currently), and whether to always run or run only if there hasn't been a commit in the last 24 hours (currently). This page looks as follows if you add the ``master`` branch on a weekly schedule, only running when there hasn't been a change in the last day:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: images/travis-cron.png\n",
    "    :width: 86%\n",
    "    :align: center    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will discuss how you can process test coverage with ``Travis CI`` [below](06-Continuous-Integration.ipynb#Analyzing-test-coverage-online-using-codecov)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous integration for Windows: ``Appveyor``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``GitHub Actions``, the new kid on the block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing test coverage online using ``codecov``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
